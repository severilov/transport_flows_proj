{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import data_handler as dh\n",
    "import model as md\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\| \\nabla f(t^k) \\|_2 * 2\\|t^0 - t^k\\|_2 $\n",
    "\n",
    "$2\\|t^0 - t^k\\|_2$\n",
    "\n",
    "$5\\|t^0\\|_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = -100\n",
    "\n",
    "matrix = [[np.nan, x, 0.5 - x, np.nan], [np.nan, np.nan, np.nan, x], \n",
    "          [np.nan, np.nan, np.nan, 0.5 - x], [np.nan, np.nan, np.nan, np.nan]]\n",
    "\n",
    "L = np.nansum(matrix, axis=1)\n",
    "W = np.nansum(matrix, axis=0)\n",
    "people_num = np.nansum(L)\n",
    "\n",
    "print(L)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net_name = 'SiouxFalls_net.tntp'\n",
    "trips_name = 'SiouxFalls_trips.tntp'\n",
    "\n",
    "handler = dh.DataHandler()\n",
    "graph_data = handler.GetGraphData(net_name, \n",
    "                                  columns=['init_node', \n",
    "                                           'term_node', 'capacity', 'free_flow_time'])\n",
    "graph_correspondences, total_od_flow = handler.GetGraphCorrespondences(trips_name)\n",
    "\n",
    "graph_data['graph_table'].head()\n",
    "graph_table = graph_data['graph_table']\n",
    "n = np.max(graph_table['init_node'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data['graph_table'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costs_func(df, i, j, column):\n",
    "    rows = df.loc[df['init_node'] == i]\n",
    "    columns = rows.loc[df['term_node'] == j]\n",
    "    c = columns[column]\n",
    "    print(rows)\n",
    "    try:\n",
    "        c = int(c)\n",
    "        return c\n",
    "    except TypeError: # если не пересекается район i с районом j\n",
    "        return np.nan\n",
    "\n",
    "def create_T(df):\n",
    "    T = np.full((n, n), np.nan, dtype=np.double)\n",
    "    \n",
    "    i_matrix = df['init_node'].to_numpy()\n",
    "    j_matrix = df['term_node'].to_numpy()\n",
    "    \n",
    "    for i in i_matrix:\n",
    "        for j in j_matrix:\n",
    "            data = df.loc[(df['init_node'] == i) & \n",
    "                             (df['term_node'] == j)]\n",
    "            if not data.empty:\n",
    "                T[i-1][j-1] = data['free_flow_time'].to_numpy()[0]\n",
    "    return T\n",
    "\n",
    "def create_cor_matr(dictnr):\n",
    "    correspondence_matrix = np.full((n, n), np.nan, dtype=np.double)\n",
    "    i = 1\n",
    "    if n > 1:\n",
    "        for key in dictnr.keys(): #dictnr[i].keys()\n",
    "            for k, v in zip(dictnr[i]['targets'], dictnr[i]['corrs']):\n",
    "                correspondence_matrix[key - 1][k - 1] = v # костыль!\n",
    "            i += 1\n",
    "    else:\n",
    "        for key in dictnr.keys():\n",
    "            for k, v in zip(dictnr[i][key].keys(), dictnr[i][key].values()):\n",
    "                correspondence_matrix[int(key) - 1][int(k)] = v\n",
    "    # print('corr mtrx: ', correspondence_matrix)\n",
    "    return correspondence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondence_matrix = create_cor_matr(graph_correspondences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = graph_data['graph_table']\n",
    "df[df['init_node'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['init_node'].unique())\n",
    "print(np.sort(df['term_node'].unique()))\n",
    "print(df['free_flow_time'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = create_T(df)\n",
    "np.savetxt('T.csv', T, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributor_L_W(array):\n",
    "    max_value = np.max(array)\n",
    "    max_value_index = np.where(array == np.max(array))\n",
    "    \n",
    "    unique, counts = np.unique(array, return_counts=True)\n",
    "    array_dict = dict(zip(unique, counts))\n",
    "    try:\n",
    "        zero_num = array_dict[0]\n",
    "    except KeyError:\n",
    "        print('this array without 0')\n",
    "        return array\n",
    "    array[max_value_index] = max_value - zero_num\n",
    "    for index in np.where(array == 0)[0]:\n",
    "        array[index] = 1.0\n",
    "    \n",
    "    return array\n",
    "\n",
    "    def get_t_from_shortest_distances(self, n, graph_data):\n",
    "\n",
    "        targets = []\n",
    "        df = graph_data['graph_table']\n",
    "        T = None\n",
    "        i = 0\n",
    "        for source in range(n):\n",
    "\n",
    "            targets = [source]\n",
    "            targets += range(0, n)\n",
    "\n",
    "            graph_table = graph_data['graph_table']\n",
    "\n",
    "            graph = tg.TransportGraph(graph_table,\n",
    "                                      graph_data['links number'],\n",
    "                                      graph_data['nodes number'])\n",
    "\n",
    "\n",
    "            t_exp = np.array(df['free_flow_time'], dtype='float64').flatten()\n",
    "            distances, pred_map = graph.shortest_distances(source=source,\n",
    "                                                           targets=targets,\n",
    "                                                           times=t_exp)\n",
    "\n",
    "            if i == 0:\n",
    "                T = distances[1:]\n",
    "            else:\n",
    "                T = np.vstack([T, distances[1:]])\n",
    "            targets = []\n",
    "            i += 1\n",
    "\n",
    "        return T\n",
    "\n",
    "def _index_nodes(self, graph_table, graph_correspondences):\n",
    "    table = graph_table.copy()\n",
    "    inits = np.unique(table['init_node'][table['init_node_thru'] == False])\n",
    "    terms = np.unique(table['term_node'][table['term_node_thru'] == False])\n",
    "    through_nodes = np.unique([table['init_node'][table['init_node_thru'] == True],\n",
    "                                   table['term_node'][table['term_node_thru'] == True]])\n",
    "\n",
    "    nodes = np.concatenate((inits, through_nodes, terms))\n",
    "    nodes_inds = list(zip(nodes, np.arange(len(nodes))))\n",
    "    init_to_ind = dict(nodes_inds[: len(inits) + len(through_nodes)])\n",
    "    term_to_ind = dict(nodes_inds[len(inits):])\n",
    "\n",
    "    table['init_node'] = table['init_node'].map(init_to_ind)\n",
    "    table['term_node'] = table['term_node'].map(term_to_ind)\n",
    "    correspondences = {}\n",
    "    for origin, dests in graph_correspondences.items():\n",
    "        dests = copy.deepcopy(dests)\n",
    "        correspondences[init_to_ind[origin]] = {'targets': list(map(term_to_ind.get, dests['targets'])),\n",
    "                                                    'corrs': dests['corrs']}\n",
    "\n",
    "    inds_to_nodes = dict(zip(range(len(nodes)), nodes))\n",
    "    return inds_to_nodes, correspondences, table\n",
    "\n",
    "def get_T_from_t(self, t, graph_data, graph_correspondences):\n",
    "\n",
    "    result = {}\n",
    "    result['zone travel times'] = {}\n",
    "\n",
    "    import transport_graph as tg\n",
    "\n",
    "    inds_to_nodes, graph_correspondences_, graph_table_ = self._index_nodes(graph_data['graph_table'],\n",
    "                                                                                   graph_correspondences)\n",
    "\n",
    "    # print('data handler: ', len(inds_to_nodes), graph_data['links number'])\n",
    "    graph_dh = tg.TransportGraph(graph_table_, len(inds_to_nodes), graph_data['links number'])\n",
    "\n",
    "    for source in graph_correspondences_:\n",
    "\n",
    "        targets = graph_correspondences_[source]['targets']\n",
    "        travel_times, _ = graph_dh.shortest_distances(source, targets, t)\n",
    "        # print('in model.py, travel_times: ', travel_times)\n",
    "        # mapping nodes' indices to initial nodes' names:\n",
    "        source_nodes = [inds_to_nodes[source]] * len(targets)\n",
    "        target_nodes = list(map(inds_to_nodes.get, targets))\n",
    "        result['zone travel times'].update(zip(zip(source_nodes, target_nodes), travel_times))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_dict = handler.get_T_from_t(graph_data['graph_table']['free_flow_time'],  graph_data, graph_correspondences)  # np.array([[0.0, 0.5], [0.5, 0.0]]) #\n",
    "T = np.full((n, n), np.inf)\n",
    "for key in T_dict['zone travel times'].keys():\n",
    "    T[key[0] - 1][key[1] - 1] = T_dict['zone travel times'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подумаем над T\n",
    "В данных по Москве время в минутах. В этих данных время по часам! ('Time: hours, distance: miles'). Переведём их в минуты. Также T занулённое, там, где стоят nan, поставим по 100 часов"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T = T * 60"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import copy\n",
    "\n",
    "buf_T = copy.copy(T)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "T = np.nan_to_num(buf_T, nan=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.nansum(correspondence_matrix, axis=1)\n",
    "W = np.nansum(correspondence_matrix, axis=0)\n",
    "people_num = np.nansum(L)\n",
    "\n",
    "L = distributor_L_W(L)\n",
    "W = distributor_L_W(W)\n",
    "\n",
    "L = L / np.nansum(L)\n",
    "W = W / np.nansum(W)\n",
    "print('people_num: ', people_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(~np.isnan(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sinkhorn(k, lambda_W_prev, lambda_L_prev):    \n",
    "    lambda_L = np.full((n, ), 0.0, dtype=np.double)\n",
    "    lambda_W = np.full((n, ), 0.0, dtype=np.double)\n",
    "    \n",
    "    if k % 2 == 0:\n",
    "        lambda_W = lambda_W_prev\n",
    "        lambda_L = np.log(np.nansum(\n",
    "            (np.exp(-lambda_W_prev - 1 - cost_matrix)).T \n",
    "            / L, axis = 0\n",
    "            ))\n",
    "    else:\n",
    "        lambda_L = lambda_L_prev\n",
    "        lambda_W = np.log(np.nansum(\n",
    "            (np.exp(-lambda_L - 1 - cost_matrix.T)).T\n",
    "            / W, axis=0\n",
    "            ))\n",
    "        \n",
    "    return lambda_W, lambda_L\n",
    "\n",
    "def iterate(cost_matrix, L, W, num_iter, eps):\n",
    "    \n",
    "    lambda_L = np.full((n, ), 0.0, dtype=np.double)\n",
    "    lambda_W = np.full((n, ), 0.0, dtype=np.double)\n",
    "    \n",
    "    for k in range(num_iter):\n",
    "        \n",
    "        lambda_Wn, lambda_Ln = Sinkhorn(k, lambda_W, lambda_L)\n",
    "        \n",
    "        delta = np.linalg.norm(np.concatenate((lambda_Ln - lambda_L, \n",
    "                                               lambda_Wn - lambda_W)))\n",
    "        \n",
    "        lambda_L, lambda_W = lambda_Ln, lambda_Wn \n",
    "        \n",
    "        if delta < eps:\n",
    "            break\n",
    "    \n",
    "    r = rec_d_i_j(lambda_Ln, lambda_Wn, cost_matrix)\n",
    "    return r\n",
    "\n",
    "def rec_d_i_j(lambda_L, lambda_W, cost_matrix):\n",
    "    er = np.exp( -1 - cost_matrix - (np.reshape(lambda_L, (n, 1)) + lambda_W))\n",
    "    return er * people_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 2500\n",
    "alpha, beta = 1.0, 1.0\n",
    "alpha_range  = np.arange(0.0, 1.0, 0.0001)\n",
    "\n",
    "best_matrix = None\n",
    "min_reconstruction_error = np.inf\n",
    "best_alpha, best_beta = np.nan, np.nan\n",
    "\n",
    "er_list = []\n",
    "\n",
    "for alpha_idx in range(len(alpha_range)):\n",
    "    alpha = alpha_range[alpha_idx]\n",
    "    cost_matrix = np.nan_to_num(T ** beta * alpha, nan=100)\n",
    "\n",
    "    rec = iterate(cost_matrix, L, W, num_iter, eps=10**(-3))    \n",
    "    er = np.linalg.norm(rec - np.nan_to_num(correspondence_matrix, nan=0.0))\n",
    "    er_list.append(er)\n",
    "\n",
    "    if er < min_reconstruction_error:\n",
    "        min_reconstruction_error = er\n",
    "        best_alpha = alpha_range[alpha_idx]\n",
    "        best_matrix = rec\n",
    "\n",
    "        print(\n",
    "            'alpha= ', best_alpha\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_list[0] - min_reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8)) \n",
    "plt.scatter(alpha_range, er_list)\n",
    "# plt.ylim(0, 2)\n",
    "plt.ylim(10265, 10300)\n",
    "plt.xlim(-0.02, 0.02)\n",
    "plt.ylabel('Невязка')\n",
    "plt.xlabel('alpha')\n",
    "plt.show()\n",
    "fig.savefig('best_sink_gamma' + str(len(alpha_range)) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n / np.nansum(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best recovery corr matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in best_matrix:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in correspondence_matrix:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-stage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Много итераций Синхорна по расчету корреспонденций, одна итерация унивесрального метода (тут ищутся кратчайшие пути и все такое - то есть это долго), потом снова много итераций Синхорна и снова одна итерация универсального метода и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_dict(corr_matrix):\n",
    "    d = {}\n",
    "    list_of_dict = []\n",
    "    n = np.shape(corr_matrix)[0]\n",
    "    buf_l = []\n",
    "    buf_ind = []\n",
    "    for i in range(1, n + 1):\n",
    "        \n",
    "        for j in range(1, n + 1):\n",
    "            buf_ind.append(int(j))\n",
    "            buf_l.append(float(corr_matrix[i-1][j-1]))\n",
    "            \n",
    "        if i in d:\n",
    "            d[i].append(dict(zip(buf_ind, buf_l)))\n",
    "        else:\n",
    "            d[i] = dict(zip(buf_ind, buf_l))\n",
    "            \n",
    "        buf_ind = []\n",
    "        buf_l = []\n",
    "    \n",
    "#     print(list_of_dict)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_correcpondences_dict = matrix_to_dict(best_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = md.Model(graph_data, best_correcpondences_dict, \n",
    "                 total_od_flow, mu = 0, rho = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, eps_abs in enumerate(np.logspace(1,3,1)):\n",
    "    print(i, eps_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 10000\n",
    "\n",
    "for i, eps_abs in enumerate(np.logspace(1,3,1)):\n",
    "    \n",
    "    print('eps_abs =', eps_abs)\n",
    "    solver_kwargs = {'eps_abs': eps_abs,\n",
    "                     'max_iter': max_iter}\n",
    "    tic = time.time()\n",
    "    result = model.find_equilibrium(solver_name = 'ustf', \n",
    "                                    solver_kwargs = solver_kwargs, \n",
    "                                    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "print('Elapsed time: {:.0f} sec'.format(toc - tic))\n",
    "    \n",
    "print('Time ratio =', np.max(result\n",
    "                                ['times'] / graph_data['graph_table']\n",
    "                                ['Free Flow Time']))\n",
    "print('Flow excess =', np.max(result\n",
    "                                ['flows'] / graph_data['graph_table']\n",
    "                                ['Capacity']) - 1, end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transport",
   "language": "python",
   "name": "transport"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
